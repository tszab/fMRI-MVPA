{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Classification of Emotional-Task Related fMRI Data"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T10:11:51.483188Z","iopub.status.busy":"2022-12-13T10:11:51.482240Z","iopub.status.idle":"2022-12-13T10:11:51.490290Z","shell.execute_reply":"2022-12-13T10:11:51.489138Z","shell.execute_reply.started":"2022-12-13T10:11:51.483145Z"},"trusted":true},"outputs":[],"source":["from sklearn.svm import LinearSVC, SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","\n","import os\n","from tqdm.notebook import tqdm\n","from copy import deepcopy\n","from itertools import combinations\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","import nibabel as nib"]},{"cell_type":"markdown","metadata":{},"source":["## Main constants"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T10:11:51.469912Z","iopub.status.busy":"2022-12-13T10:11:51.469517Z","iopub.status.idle":"2022-12-13T10:11:51.476572Z","shell.execute_reply":"2022-12-13T10:11:51.475194Z","shell.execute_reply.started":"2022-12-13T10:11:51.469881Z"},"trusted":true},"outputs":[],"source":["DATASET_FILE = r'/kaggle/input/ds003548/trials/labels.csv'\n","SELECTED_SUBJECTS = list(range(1, 17, 1))\n","RUN_SET_SPLITS = {\n","    'train': [1, 2, 3, 4, 5],\n","    'test': ['-']\n","}\n","SELECTED_CLASSES = {'neutral': 0, 'happy': 1, 'sad': 2, 'angry': 3}"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset handling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:11:48.740135Z","iopub.status.busy":"2022-12-13T11:11:48.739633Z","iopub.status.idle":"2022-12-13T11:11:48.763652Z","shell.execute_reply":"2022-12-13T11:11:48.762119Z","shell.execute_reply.started":"2022-12-13T11:11:48.740068Z"},"trusted":true},"outputs":[],"source":["def load_set(set_df: pd.DataFrame, flatten: bool = True, time_first: bool = True, averaged_over_time: bool = False) -> np.ndarray:\n","    data = []\n","    labels = []\n","    for _, row in set_df.iterrows():\n","        # Load image (change paths to be compatible with Kaggle)\n","        data_path = row['ext_frmi_pths'].replace(r'C:\\Users\\tormi\\Documents\\Egyetem\\PhD\\Learn\\IDA\\HW\\data', r'/kaggle/input/ds003548')\n","        data_path = data_path.replace('\\\\', os.sep)\n","        loaded_data = nib.load(data_path).get_fdata()\n","        \n","        # Loaded dimensions height x width x slices x times\n","        if time_first:\n","            loaded_data = loaded_data.transpose(3, 0, 1, 2)\n","            \n","            # Feature vector\n","            if flatten:\n","                loaded_data = loaded_data.reshape((loaded_data.shape[0], loaded_data.shape[1], -1))\n","                loaded_data = loaded_data.reshape((loaded_data.shape[0], -1))\n","\n","            if averaged_over_time:\n","                loaded_data = loaded_data.mean(axis=0, keepdim=True)\n","\n","        elif flatten:\n","            # Feature vector\n","            loaded_data = loaded_data.reshape((-1, loaded_data.shape[-1]))\n","\n","            if averaged_over_time:\n","                loaded_data = loaded_data.mean(axis=-1, keepdim=True)\n","        \n","        data.append(loaded_data)\n","        # Label constants to be in ascending order\n","        row_labels = np.zeros((len(loaded_data), len(SELECTED_CLASSES.keys())))\n","        row_labels[:, SELECTED_CLASSES[row['trial_types']]] = 1\n","        labels.append(row_labels.argmax(-1))\n","\n","    data = np.concatenate(data, axis=0)\n","    labels = np.concatenate(labels, axis=0)\n","\n","    return data, labels\n","\n","def load_and_split_dataset(dataset_file: str, selected_classes: list, selected_subjects: list, train_runs: list, test_runs: list, scale: bool = True):\n","    # Load dataset\n","    dataset_file = pd.read_csv(dataset_file, sep=';')\n","    dataset_numpy = dataset_file.to_numpy()\n","    \n","    # Filter subjects and classes\n","    subject_filter = dataset_numpy[:, 1] == selected_subjects[0]\n","    if len(selected_subjects) > 1:\n","        for subject in selected_subjects[1:]:\n","            subject_filter += (dataset_numpy[:, 1] == subject)\n","\n","    class_filter = dataset_numpy[:, 4] == selected_classes[0]\n","    if len(selected_classes) > 1:\n","        for class_type in selected_classes[1:]:\n","            class_filter += (dataset_numpy[:, 4] == class_type)\n","\n","    train_run_filter = dataset_numpy[:, 2] == train_runs[0]\n","    if len(train_runs) > 1:\n","        for run in train_runs[1:]:\n","            train_run_filter += (dataset_numpy[:, 2] == run)\n","\n","    test_run_filter = dataset_numpy[:, 2] == test_runs[0]\n","    if len(test_runs) > 1:\n","        for run in test_runs[1:]:\n","            test_run_filter += (dataset_numpy[:, 2] == run)\n","\n","    train_set_file = dataset_numpy[subject_filter * class_filter * train_run_filter]\n","    test_set_file = dataset_numpy[subject_filter * class_filter * test_run_filter]\n","\n","    train_set_file = pd.DataFrame(data=train_set_file, columns=dataset_file.columns)\n","    test_set_file = pd.DataFrame(data=test_set_file, columns=dataset_file.columns)\n","\n","    # Load data sets and labels\n","    train_data, train_labels = load_set(train_set_file)\n","    if not test_set_file.empty:\n","        test_data, test_labels = load_set(test_set_file)\n","    else:\n","        test_data, test_labels = None, None\n","\n","    # Standardize data\n","    if scale:\n","        sc_train = StandardScaler()\n","        train_data = sc_train.fit_transform(train_data)\n","\n","        if not test_set_file.empty:\n","            sc_test = StandardScaler()\n","            test_data = sc_test.fit_transform(test_data)\n","\n","    return train_data, train_labels, test_data, test_labels"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Kernel SVM Subject-Wise Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dict for saving metrics and best fold-model\n","subject_linear_svcs = dict()\n","\n","folds = len(RUN_SET_SPLITS['train'])\n","with tqdm(total=folds * len(SELECTED_SUBJECTS), leave=True) as pbar:\n","    for subject in SELECTED_SUBJECTS:\n","        print(f'Subject {subject}')\n","        \n","        # Subject-related metrics\n","        subject_linear_svcs[str(subject)] = {\n","            'model': None,\n","            'accuracies': [],\n","            'recall': [],\n","            'precision': [],\n","            'fscore': []\n","        }\n","        \n","        # Leave-one-run-out folds\n","        best_acc = 0.\n","        for fold in range(folds):\n","            print(f'Fold {fold}')\n","            try:\n","                # Gather train and test runs\n","                train_runs = deepcopy(RUN_SET_SPLITS['train'])\n","                train_runs.remove(fold + 1)\n","                test_runs = [fold + 1]\n","                \n","                # Load folds\n","                fold_train_data, fold_train_labels, fold_test_data, fold_test_labels = \\\n","                    load_and_split_dataset(DATASET_FILE, list(SELECTED_CLASSES.keys()), [subject], train_runs, test_runs)\n","                \n","                # Subject-wise SVM\n","                linear_svc = SVC(verbose=0, C=0.1, kernel='linear', max_iter=1000)\n","                linear_svc.fit(fold_train_data, fold_train_labels)\n","                predictions = linear_svc.predict(fold_test_data)\n","                \n","                # Metric calculations based on confusion matrix\n","                fold_acc = accuracy_score(predictions, fold_test_labels)\n","                conf_matrix = confusion_matrix(fold_test_labels, predictions)\n","                diag = np.eye(*conf_matrix.shape, dtype=bool)\n","                recall = np.sum(conf_matrix, axis=-1, keepdims=True)\n","                recall = np.where(recall > 0, (conf_matrix[diag] / recall.T).T, np.zeros_like(recall))\n","                precision = np.sum(conf_matrix, axis=0, keepdims=True)\n","                precision = np.where(precision > 0, (conf_matrix[diag] / precision), np.zeros_like(precision)).T\n","                accuracy = np.sum(conf_matrix[diag]) / np.sum(conf_matrix)\n","                \n","                # Save metrics\n","                print(f'Fold accuracy: {fold_acc * 100}%')\n","                if fold_acc > best_acc:\n","                    best_acc = fold_acc\n","                    subject_linear_svcs[str(subject)]['model'] = deepcopy(linear_svc)\n","                subject_linear_svcs[str(subject)]['accuracies'].append(fold_acc)\n","\n","                fscore = 2 * precision * recall / (precision + recall)\n","                fscore = [value.item() for value in fscore]\n","                subject_linear_svcs[str(subject)]['fscore'].append(fscore)\n","\n","                recall = [value.item() for value in recall]\n","                precision = [value.item() for value in precision]\n","                subject_linear_svcs[str(subject)]['recall'].append(recall)\n","                subject_linear_svcs[str(subject)]['precision'].append(precision)\n","                \n","            except Exception as e:\n","                print('Warning! Something went wrong!')\n","                print(str(e))\n","            \n","            pbar.update(1)\n","\n","# Save trainin metrics and SVMs\n","from joblib import dump\n","subject_linear_svcs = dump(r'/kaggle/working/subject_linear_svcs.joblib')"]},{"cell_type":"markdown","metadata":{},"source":["## Metric visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T10:23:50.428965Z","iopub.status.busy":"2022-12-13T10:23:50.428454Z","iopub.status.idle":"2022-12-13T10:24:53.907098Z","shell.execute_reply":"2022-12-13T10:24:53.905569Z","shell.execute_reply.started":"2022-12-13T10:23:50.428928Z"},"trusted":true},"outputs":[],"source":["# Load trainin metrics and SVMs\n","from joblib import load\n","subject_linear_svcs = load(r'/kaggle/working/subject_linear_svcs.joblib')\n","\n","# Subject-wise accuracy scores\n","for_df = {\n","    'accuracy': [],\n","    'subject': [],\n","}\n","for subject in SELECTED_SUBJECTS:\n","    for_df['accuracy'].extend(subject_linear_svcs[str(subject)]['accuracies'])\n","    for_df['subject'].extend([f's{subject}'] * len(subject_linear_svcs[str(subject)]['accuracies']))\n","df = pd.DataFrame.from_dict(for_df)\n","\n","# Plot scores\n","sns.set_theme(style=\"whitegrid\")\n","g = sns.catplot(\n","    data=df, kind=\"bar\",\n","    x=\"subject\", y=\"accuracy\", palette=\"dark\", alpha=.7, height=8\n",")\n","g.despine(left=True)\n","g.set_axis_labels(\"Patient\", \"Accuracy\")\n","g.fig.suptitle(\"Classification Accuracies of Separate SVMs per Subject\")\n","g.set(ylim=(0, 1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T13:32:26.852315Z","iopub.status.busy":"2022-12-12T13:32:26.851788Z","iopub.status.idle":"2022-12-12T13:32:26.866503Z","shell.execute_reply":"2022-12-12T13:32:26.864958Z","shell.execute_reply.started":"2022-12-12T13:32:26.852264Z"},"trusted":true},"outputs":[],"source":["# Class-wise other metrics\n","for_df = {\n","    'fscores': [],\n","    'precisions': [],\n","    'recalls': [],\n","    'classes': [],\n","}\n","for subject in SELECTED_SUBJECTS:\n","    recalls = np.array(subject_linear_svcs[str(subject)]['recall'])\n","    precisions = np.array(subject_linear_svcs[str(subject)]['precision'])\n","    fscores = np.array(subject_linear_svcs[str(subject)]['fscore'])\n","    for class_idx, class_id in enumerate(SELECTED_CLASSES.keys()):\n","        for_df['fscores'].extend(list(fscores[:, class_idx]))\n","        for_df['precisions'].extend(list(precisions[:, class_idx]))\n","        for_df['recalls'].extend(list(recalls[:, class_idx]))\n","        for_df['classes'].extend([f'{class_id}'] * recalls.shape[0])\n","df = pd.DataFrame.from_dict(for_df)\n","\n","def plot_df(df, x, y, x_title, title):\n","    sns.set_theme(style=\"whitegrid\")\n","    g = sns.catplot(\n","        data=df, kind=\"bar\",\n","        x=x, y=y, palette=\"dark\", alpha=.7, height=8\n","    )\n","    g.despine(left=True)\n","    g.set_axis_labels(\"Class\", x_title)\n","    g.fig.suptitle(title)\n","    g.set(ylim=(0, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T13:32:13.512491Z","iopub.status.busy":"2022-12-12T13:32:13.512061Z","iopub.status.idle":"2022-12-12T13:32:13.926082Z","shell.execute_reply":"2022-12-12T13:32:13.924994Z","shell.execute_reply.started":"2022-12-12T13:32:13.512459Z"},"trusted":true},"outputs":[],"source":["plot_df(df, 'classes', 'recalls', 'Recall', '')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T13:32:15.540252Z","iopub.status.busy":"2022-12-12T13:32:15.539544Z","iopub.status.idle":"2022-12-12T13:32:15.920465Z","shell.execute_reply":"2022-12-12T13:32:15.919487Z","shell.execute_reply.started":"2022-12-12T13:32:15.540213Z"},"trusted":true},"outputs":[],"source":["plot_df(df, 'classes', 'precisions', 'Precision', '')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T13:32:20.153580Z","iopub.status.busy":"2022-12-12T13:32:20.152813Z","iopub.status.idle":"2022-12-12T13:32:20.557007Z","shell.execute_reply":"2022-12-12T13:32:20.555485Z","shell.execute_reply.started":"2022-12-12T13:32:20.153528Z"},"trusted":true},"outputs":[],"source":["plot_df(df, 'classes', 'fscores', 'F-Score', '')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## SVM coefficient visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T12:20:10.716969Z","iopub.status.busy":"2022-12-13T12:20:10.716517Z","iopub.status.idle":"2022-12-13T12:20:13.711426Z","shell.execute_reply":"2022-12-13T12:20:13.710205Z","shell.execute_reply.started":"2022-12-13T12:20:10.716932Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from skimage.util import montage\n","from skimage import color\n","\n","# Gather coefficients and data w.r.t a subject or subjects\n","subj_coefs = []\n","subj_data = []\n","\n","subjects = [1]\n","for subject in subjects:\n","    fold_train_data, _, _, _ = \\\n","        load_and_split_dataset(DATASET_FILE, list(SELECTED_CLASSES.keys()), [subject], RUN_SET_SPLITS['train'], ['-'], scale=False)\n","    fold_train_data = np.split(fold_train_data, fold_train_data.shape[0]//15)\n","    fold_train_data = np.mean(fold_train_data, axis=1)\n","    subj_data.append(fold_train_data)\n","    \n","    subj_coefs.append(\n","        np.expand_dims(subject_linear_svcs[str(subject)]['model'].coef_, axis=0)\n","    )\n","\n","subj_data = np.concatenate(subj_data, axis=0)\n","subj_data = np.mean(subj_data, axis=0)\n","subj_data = subj_data.reshape(61, 61, 37).transpose(2, 0, 1)\n","\n","subj_coefs = np.concatenate(subj_coefs, axis=0)\n","subj_coefs = np.mean(np.mean(subj_coefs, axis=0), axis=0)\n","subj_coefs = subj_coefs.reshape(61, 61, 37).transpose(2, 0, 1)\n","subj_coefs_pos = np.where(subj_coefs > 0, subj_coefs, 0)\n","subj_coefs_neg = np.where(subj_coefs < 0, np.abs(subj_coefs), 0)\n","\n","# Visualize activation maps based on SVM Coefficients\n","plt.figure(figsize=(20, 20))\n","plt.imshow(montage(subj_coefs_pos[1:]))\n","plt.imshow(montage(subj_coefs_neg[1:]))\n","plt.colorbar()\n","plt.imshow(montage(subj_data[1:]), cmap=\"gray\", alpha=0.5)\n","plt.grid(None)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T12:20:19.117468Z","iopub.status.busy":"2022-12-13T12:20:19.116205Z","iopub.status.idle":"2022-12-13T12:20:20.194824Z","shell.execute_reply":"2022-12-13T12:20:20.193547Z","shell.execute_reply.started":"2022-12-13T12:20:19.117407Z"},"trusted":true},"outputs":[],"source":["# Visualize wighted activation maps based on SVM Coefficients\n","plt.figure(figsize=(20, 20))\n","plt.imshow(montage(subj_coefs_pos[1:] * subj_data[1:]))\n","plt.imshow(montage(subj_coefs_neg[1:] * subj_data[1:]))\n","plt.colorbar()\n","plt.imshow(montage(subj_data[1:]), cmap=\"gray\", alpha=0.5)\n","plt.grid(None)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"pt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"fdd96f0c715a1bc4e1bb5609a8ddfb420569e343ee819478f5c3445b6e8b2467"}}},"nbformat":4,"nbformat_minor":4}
