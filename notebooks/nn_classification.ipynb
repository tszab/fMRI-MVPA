{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Neural Network for fMRI Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class fMRIDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_path: str, \n",
    "        selected_subjects: list = None,\n",
    "        selected_runs: list = None,\n",
    "        selected_classes: list = None,\n",
    "        encode_labels: bool = True,\n",
    "        exclude_end: bool = True,\n",
    "        exclude_blank: bool = False,\n",
    "        exclude_scrambled: bool = False,\n",
    "        normalize_data: bool = True,\n",
    "        time_first: bool = True\n",
    "    ):\n",
    "        self.selected_subjects = selected_subjects\n",
    "        self.selected_runs = selected_runs\n",
    "        self.selected_classes = selected_classes\n",
    "        self.encode_labels = encode_labels\n",
    "        self.exclude_end = exclude_end\n",
    "        self.exclude_blank = exclude_blank\n",
    "        self.exclude_scrambled = exclude_scrambled\n",
    "        self.normalize_data = normalize_data\n",
    "        self.time_first = time_first\n",
    "        self.data_info, self.class_ids, self.subject_ids, self.run_ids = self.__load_data(data_path)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index: int) -> int:\n",
    "        try:\n",
    "            data_record = self.data_info.iloc[index]\n",
    "        except:\n",
    "            print(index)\n",
    "            raise\n",
    "\n",
    "        fmri_data = nib.load(\n",
    "            data_record['ext_frmi_pths']\n",
    "        )\n",
    "        fmri_data = torch.from_numpy(\n",
    "            fmri_data.get_fdata()\n",
    "        ).float()\n",
    "        if not self.time_first:\n",
    "            fmri_data = fmri_data.permute(2, 3, 0, 1).contiguous()\n",
    "        else:\n",
    "            fmri_data = fmri_data.permute(3, 0, 1, 2).contiguous()\n",
    "\n",
    "        fmri_label = np.array(data_record['trial_ids'])\n",
    "        fmri_label = torch.from_numpy(fmri_label).float()\n",
    "        if self.encode_labels:\n",
    "            fmri_label = one_hot(fmri_label.long(), num_classes=len(self.class_ids)).float()\n",
    "\n",
    "        if self.normalize_data:\n",
    "            fmri_data = (fmri_data - fmri_data.mean()) / fmri_data.std()\n",
    "\n",
    "        fmri_label = fmri_label.repeat(fmri_data.shape[0], 1)\n",
    "\n",
    "        return fmri_data, fmri_label\n",
    "\n",
    "    def __load_data(self, data_path: str):\n",
    "        data = pd.read_csv(data_path, sep=';')\n",
    "\n",
    "        if self.exclude_end:\n",
    "            data = data.loc[data['trial_types'] != 'end']\n",
    "            data = data.reset_index(drop=True)\n",
    "        if self.exclude_blank:\n",
    "            data = data.loc[data['trial_types'] != 'blank']\n",
    "            data = data.reset_index(drop=True)\n",
    "        if self.exclude_scrambled:\n",
    "            data = data.loc[data['trial_types'] != 'scrambled']\n",
    "            data = data.reset_index(drop=True)\n",
    "\n",
    "        class_ids = np.unique(data['trial_ids']).astype(np.longlong)\n",
    "\n",
    "        if self.selected_subjects is not None:\n",
    "            data = data.loc[data['subjects'].isin(self.selected_subjects)]\n",
    "            data = data.reset_index(drop=True)\n",
    "        if self.selected_runs is not None:\n",
    "            data = data.loc[data['runs'].isin(self.selected_runs)]\n",
    "            data = data.reset_index(drop=True)\n",
    "        if self.selected_classes is not None:\n",
    "            if isinstance(self.selected_classes[0], str):\n",
    "                data = data.loc[data['trial_types'].isin(self.selected_classes)]\n",
    "                data = data.reset_index(drop=True)\n",
    "            elif isinstance(self.selected_classes[0], int):\n",
    "                data = data.loc[data['trial_ids'].isin(self.selected_classes)]\n",
    "                data = data.reset_index(drop=True)\n",
    "            else:\n",
    "                raise AttributeError('Not supported class types! Only a list of str or int values can be given!')\n",
    "        \n",
    "        subject_ids = np.unique(data['subjects'])\n",
    "        run_ids = np.unique(data['runs'])\n",
    "\n",
    "        return data, class_ids, subject_ids, run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def split_data_set(\n",
    "    dataset: fMRIDataset, \n",
    "    train_test_ratio: float = 0.8, \n",
    "    val_ratio: float = 0.1, \n",
    "    shuffle: bool = False, \n",
    "    seed: int = 42,\n",
    "):\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    val_indices = []\n",
    "\n",
    "    if shuffle:\n",
    "        rnd_state = np.random.RandomState(seed=seed)\n",
    "\n",
    "    didf = dataset.data_info\n",
    "    for class_id in dataset.class_ids:\n",
    "        for subject_id in dataset.subject_ids:\n",
    "            selection = didf.query(f'trial_ids == {class_id} & subjects == {subject_id}').index.to_numpy()\n",
    "            if shuffle:  \n",
    "                rnd_state.shuffle(selection)\n",
    "            \n",
    "            train_indices.append(\n",
    "                selection[:int(len(selection) * (train_test_ratio - val_ratio))]\n",
    "            )\n",
    "            test_indices.append(\n",
    "                selection[int(len(selection) * (train_test_ratio)):]\n",
    "            )\n",
    "            if val_ratio > 0:\n",
    "                val_indices.append(\n",
    "                    selection[int(len(selection) * (train_test_ratio - val_ratio)) : int(len(selection) * (train_test_ratio))]\n",
    "                )\n",
    "\n",
    "    train_indices = np.concatenate(train_indices, axis=-1)\n",
    "    test_indices = np.concatenate(test_indices, axis=-1)\n",
    "    if val_ratio > 0:\n",
    "        val_indices = np.concatenate(val_indices, axis=-1)\n",
    "    \n",
    "    train_set = Subset(dataset, train_indices)\n",
    "    test_set = Subset(dataset, test_indices)\n",
    "    if val_ratio > 0:\n",
    "        val_set = Subset(dataset, val_indices)\n",
    "        return train_set, test_set, val_set\n",
    "    else:\n",
    "        return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_CHANS = 79\n",
    "INPUT_CHANS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torchvision.ops import StochasticDepth\n",
    "\n",
    "from torchvision.ops.misc import Conv3dNormActivation\n",
    "from torchvision.transforms._presets import ImageClassification, InterpolationMode\n",
    "\n",
    "\n",
    "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class SqueezeExcitation3D(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This block implements the Squeeze-and-Excitation block from https://arxiv.org/abs/1709.01507 (see Fig. 1).\n",
    "    Parameters ``activation``, and ``scale_activation`` correspond to ``delta`` and ``sigma`` in eq. 3.\n",
    "\n",
    "    Args:\n",
    "        input_channels (int): Number of channels in the input image\n",
    "        squeeze_channels (int): Number of squeeze channels\n",
    "        activation (Callable[..., torch.nn.Module], optional): ``delta`` activation. Default: ``torch.nn.ReLU``\n",
    "        scale_activation (Callable[..., torch.nn.Module]): ``sigma`` activation. Default: ``torch.nn.Sigmoid``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        squeeze_channels: int,\n",
    "        activation: Callable[..., torch.nn.Module] = torch.nn.ReLU,\n",
    "        scale_activation: Callable[..., torch.nn.Module] = torch.nn.Sigmoid,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc1 = torch.nn.Conv3d(input_channels, squeeze_channels, 1)\n",
    "        self.fc2 = torch.nn.Conv3d(squeeze_channels, input_channels, 1)\n",
    "        self.activation = activation()\n",
    "        self.scale_activation = scale_activation()\n",
    "\n",
    "    def _scale(self, input: Tensor) -> Tensor:\n",
    "        scale = self.avgpool(input)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.activation(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        return self.scale_activation(scale)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        scale = self._scale(input)\n",
    "        return scale * input\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class _MBConvConfig:\n",
    "    expand_ratio: float\n",
    "    kernel: int\n",
    "    stride: int\n",
    "    input_channels: int\n",
    "    out_channels: int\n",
    "    num_layers: int\n",
    "    block: Callable[..., nn.Module]\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_mult: float, min_value: Optional[int] = None) -> int:\n",
    "        return _make_divisible(channels * width_mult, 8, min_value)\n",
    "\n",
    "\n",
    "class MBConvConfig(_MBConvConfig):\n",
    "    # Stores information listed at Table 1 of the EfficientNet paper & Table 4 of the EfficientNetV2 paper\n",
    "    def __init__(\n",
    "        self,\n",
    "        expand_ratio: float,\n",
    "        kernel: int,\n",
    "        stride: int,\n",
    "        input_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        width_mult: float = 1.0,\n",
    "        depth_mult: float = 1.0,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        input_channels = self.adjust_channels(input_channels, width_mult)\n",
    "        out_channels = self.adjust_channels(out_channels, width_mult)\n",
    "        num_layers = self.adjust_depth(num_layers, depth_mult)\n",
    "        if block is None:\n",
    "            block = MBConv\n",
    "        super().__init__(expand_ratio, kernel, stride, input_channels, out_channels, num_layers, block)\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_depth(num_layers: int, depth_mult: float):\n",
    "        return int(math.ceil(num_layers * depth_mult))\n",
    "\n",
    "\n",
    "class FusedMBConvConfig(_MBConvConfig):\n",
    "    # Stores information listed at Table 4 of the EfficientNetV2 paper\n",
    "    def __init__(\n",
    "        self,\n",
    "        expand_ratio: float,\n",
    "        kernel: int,\n",
    "        stride: int,\n",
    "        input_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        if block is None:\n",
    "            block = FusedMBConv\n",
    "        super().__init__(expand_ratio, kernel, stride, input_channels, out_channels, num_layers, block)\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cnf: MBConvConfig,\n",
    "        stochastic_depth_prob: float,\n",
    "        norm_layer: Callable[..., nn.Module],\n",
    "        se_layer: Callable[..., nn.Module] = SqueezeExcitation3D,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError(\"illegal stride value\")\n",
    "\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.SiLU\n",
    "\n",
    "        # expand\n",
    "        expanded_channels = cnf.adjust_channels(cnf.input_channels, cnf.expand_ratio)\n",
    "        if expanded_channels != cnf.input_channels:\n",
    "            layers.append(\n",
    "                Conv3dNormActivation(\n",
    "                    cnf.input_channels,\n",
    "                    expanded_channels,\n",
    "                    kernel_size=1,\n",
    "                    norm_layer=norm_layer,\n",
    "                    activation_layer=activation_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # depthwise\n",
    "        layers.append(\n",
    "            Conv3dNormActivation(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=cnf.kernel,\n",
    "                stride=cnf.stride,\n",
    "                groups=expanded_channels,\n",
    "                norm_layer=norm_layer,\n",
    "                activation_layer=activation_layer,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # squeeze and excitation\n",
    "        squeeze_channels = max(1, cnf.input_channels // 4)\n",
    "        layers.append(se_layer(expanded_channels, squeeze_channels, activation=partial(nn.SiLU, inplace=True)))\n",
    "\n",
    "        # project\n",
    "        layers.append(\n",
    "            Conv3dNormActivation(\n",
    "                expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "        self.out_channels = cnf.out_channels\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            result = self.stochastic_depth(result)\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "class FusedMBConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cnf: FusedMBConvConfig,\n",
    "        stochastic_depth_prob: float,\n",
    "        norm_layer: Callable[..., nn.Module],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError(\"illegal stride value\")\n",
    "\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.SiLU\n",
    "\n",
    "        expanded_channels = cnf.adjust_channels(cnf.input_channels, cnf.expand_ratio)\n",
    "        if expanded_channels != cnf.input_channels:\n",
    "            # fused expand\n",
    "            layers.append(\n",
    "                Conv3dNormActivation(\n",
    "                    cnf.input_channels,\n",
    "                    expanded_channels,\n",
    "                    kernel_size=cnf.kernel,\n",
    "                    stride=cnf.stride,\n",
    "                    norm_layer=norm_layer,\n",
    "                    activation_layer=activation_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # project\n",
    "            layers.append(\n",
    "                Conv3dNormActivation(\n",
    "                    expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            layers.append(\n",
    "                Conv3dNormActivation(\n",
    "                    cnf.input_channels,\n",
    "                    cnf.out_channels,\n",
    "                    kernel_size=cnf.kernel,\n",
    "                    stride=cnf.stride,\n",
    "                    norm_layer=norm_layer,\n",
    "                    activation_layer=activation_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "        self.out_channels = cnf.out_channels\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            result = self.stochastic_depth(result)\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]],\n",
    "        dropout: float,\n",
    "        stochastic_depth_prob: float = 0.2,\n",
    "        num_classes: int = 1000,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        last_channel: Optional[int] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        EfficientNet V1 and V2 main class\n",
    "\n",
    "        Args:\n",
    "            inverted_residual_setting (Sequence[Union[MBConvConfig, FusedMBConvConfig]]): Network structure\n",
    "            dropout (float): The droupout probability\n",
    "            stochastic_depth_prob (float): The stochastic depth probability\n",
    "            num_classes (int): Number of classes\n",
    "            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n",
    "            last_channel (int): The number of channels on the penultimate layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty\")\n",
    "        elif not (\n",
    "            isinstance(inverted_residual_setting, Sequence)\n",
    "            and all([isinstance(s, _MBConvConfig) for s in inverted_residual_setting])\n",
    "        ):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[MBConvConfig]\")\n",
    "\n",
    "        if \"block\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The parameter 'block' is deprecated since 0.13 and will be removed 0.15. \"\n",
    "                \"Please pass this information on 'MBConvConfig.block' instead.\"\n",
    "            )\n",
    "            if kwargs[\"block\"] is not None:\n",
    "                for s in inverted_residual_setting:\n",
    "                    if isinstance(s, MBConvConfig):\n",
    "                        s.block = kwargs[\"block\"]\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm3d\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # building first layer\n",
    "        firstconv_output_channels = inverted_residual_setting[0].input_channels\n",
    "        layers.append(\n",
    "            Conv3dNormActivation(\n",
    "                INPUT_CHANS, firstconv_output_channels, kernel_size=3, stride=2, norm_layer=norm_layer, activation_layer=nn.SiLU\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        total_stage_blocks = sum(cnf.num_layers for cnf in inverted_residual_setting)\n",
    "        stage_block_id = 0\n",
    "        for cnf in inverted_residual_setting:\n",
    "            stage: List[nn.Module] = []\n",
    "            for _ in range(cnf.num_layers):\n",
    "                # copy to avoid modifications. shallow copy is enough\n",
    "                block_cnf = copy.copy(cnf)\n",
    "\n",
    "                # overwrite info if not the first conv in the stage\n",
    "                if stage:\n",
    "                    block_cnf.input_channels = block_cnf.out_channels\n",
    "                    block_cnf.stride = 1\n",
    "\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = stochastic_depth_prob * float(stage_block_id) / total_stage_blocks\n",
    "\n",
    "                stage.append(block_cnf.block(block_cnf, sd_prob, norm_layer))\n",
    "                stage_block_id += 1\n",
    "\n",
    "            layers.append(nn.Sequential(*stage))\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
    "        lastconv_output_channels = last_channel if last_channel is not None else 4 * lastconv_input_channels\n",
    "        layers.append(\n",
    "            Conv3dNormActivation(\n",
    "                lastconv_input_channels,\n",
    "                lastconv_output_channels,\n",
    "                kernel_size=1,\n",
    "                norm_layer=norm_layer,\n",
    "                activation_layer=nn.SiLU,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout, inplace=True),\n",
    "            nn.Linear(lastconv_output_channels, num_classes),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm3d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init_range = 1.0 / math.sqrt(m.out_features)\n",
    "                nn.init.uniform_(m.weight, -init_range, init_range)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _efficientnet_conf(\n",
    "    arch: str,\n",
    "    **kwargs: Any,\n",
    ") -> Tuple[Sequence[Union[MBConvConfig, FusedMBConvConfig]], Optional[int]]:\n",
    "    inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]]\n",
    "    if arch.startswith(\"efficientnet_b\"):\n",
    "        bneck_conf = partial(MBConvConfig, width_mult=kwargs.pop(\"width_mult\"), depth_mult=kwargs.pop(\"depth_mult\"))\n",
    "        inverted_residual_setting = [\n",
    "            bneck_conf(1, 3, 1, 32, 16, 1),\n",
    "            bneck_conf(6, 3, 2, 16, 24, 2),\n",
    "            bneck_conf(6, 5, 2, 24, 40, 2),\n",
    "            bneck_conf(6, 3, 2, 40, 80, 3),\n",
    "            bneck_conf(6, 5, 1, 80, 112, 3),\n",
    "            bneck_conf(6, 5, 2, 112, 192, 4),\n",
    "            bneck_conf(6, 3, 1, 192, 320, 1),\n",
    "        ]\n",
    "        last_channel = None\n",
    "    elif arch.startswith(\"efficientnet_v2_s\"):\n",
    "        inverted_residual_setting = [\n",
    "            FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
    "            FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
    "            FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
    "            MBConvConfig(4, 3, 2, 64, 128, 6),\n",
    "            MBConvConfig(6, 3, 1, 128, 160, 9),\n",
    "            MBConvConfig(6, 3, 2, 160, 256, 15),\n",
    "        ]\n",
    "        last_channel = 1280\n",
    "    elif arch.startswith(\"efficientnet_v2_m\"):\n",
    "        inverted_residual_setting = [\n",
    "            FusedMBConvConfig(1, 3, 1, 24, 24, 3),\n",
    "            FusedMBConvConfig(4, 3, 2, 24, 48, 5),\n",
    "            FusedMBConvConfig(4, 3, 2, 48, 80, 5),\n",
    "            MBConvConfig(4, 3, 2, 80, 160, 7),\n",
    "            MBConvConfig(6, 3, 1, 160, 176, 14),\n",
    "            MBConvConfig(6, 3, 2, 176, 304, 18),\n",
    "            MBConvConfig(6, 3, 1, 304, 512, 5),\n",
    "        ]\n",
    "        last_channel = 1280\n",
    "    elif arch.startswith(\"efficientnet_v2_l\"):\n",
    "        inverted_residual_setting = [\n",
    "            FusedMBConvConfig(1, 3, 1, 32, 32, 4),\n",
    "            FusedMBConvConfig(4, 3, 2, 32, 64, 7),\n",
    "            FusedMBConvConfig(4, 3, 2, 64, 96, 7),\n",
    "            MBConvConfig(4, 3, 2, 96, 192, 10),\n",
    "            MBConvConfig(6, 3, 1, 192, 224, 19),\n",
    "            MBConvConfig(6, 3, 2, 224, 384, 25),\n",
    "            MBConvConfig(6, 3, 1, 384, 640, 7),\n",
    "        ]\n",
    "        last_channel = 1280\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type {arch}\")\n",
    "\n",
    "    return inverted_residual_setting, last_channel\n",
    "\n",
    "\n",
    "def _efficientnet(\n",
    "    inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]],\n",
    "    dropout: float,\n",
    "    last_channel: Optional[int],\n",
    "    weights: object,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> EfficientNet:\n",
    "\n",
    "    model = EfficientNet(inverted_residual_setting, dropout, last_channel=last_channel, **kwargs)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def efficientnet_b0(*, weights: object = None, progress: bool = True, **kwargs: Any\n",
    ") -> EfficientNet:\n",
    "    \"\"\"EfficientNet B0 model architecture from the `EfficientNet: Rethinking Model Scaling for Convolutional\n",
    "    Neural Networks <https://arxiv.org/abs/1905.11946>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.EfficientNet_B0_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.EfficientNet_B0_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.efficientnet.EfficientNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.EfficientNet_B0_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    inverted_residual_setting, last_channel = _efficientnet_conf(\"efficientnet_b0\", width_mult=1.0, depth_mult=1.0)\n",
    "    return _efficientnet(inverted_residual_setting, 0.2, last_channel, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "def efficientnet_v2_s(*, weights: object = None, progress: bool = True, **kwargs: Any\n",
    ") -> EfficientNet:\n",
    "    \"\"\"\n",
    "    Constructs an EfficientNetV2-S architecture from\n",
    "    `EfficientNetV2: Smaller Models and Faster Training <https://arxiv.org/abs/2104.00298>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.EfficientNet_V2_S_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.EfficientNet_V2_S_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.efficientnet.EfficientNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.EfficientNet_V2_S_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "\n",
    "    inverted_residual_setting, last_channel = _efficientnet_conf(\"efficientnet_v2_s\")\n",
    "    return _efficientnet(\n",
    "        inverted_residual_setting,\n",
    "        0.2,\n",
    "        last_channel,\n",
    "        weights,\n",
    "        progress,\n",
    "        norm_layer=partial(nn.BatchNorm3d, eps=1e-03),\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(44*64*64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view((x.shape[0] * x.shape[1], -1)).contiguous()\n",
    "        x = (x - (x.mean(-1, keepdims=True))) / x.std(-1, keepdims=True)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "DATASET_CFG = {\n",
    "    'data_path': r\"...\\data\\ds002338\\PreProcessed\\Trials\\XP1\\labels.csv\",  # need to be set\n",
    "    'selected_subjects': None,\n",
    "    'selected_runs': None,\n",
    "    'selected_classes': None,\n",
    "    'encode_labels': True,\n",
    "    'exclude_end': False,\n",
    "    'exclude_blank': False,\n",
    "    'exclude_scrambled': False,\n",
    "    'normalize_data': False,\n",
    "    'time_first': True\n",
    "}\n",
    "\n",
    "DATA_SPLIT_CFG = {\n",
    "    'train_test_ratio': 0.8,\n",
    "    'val_ratio': 0.2,\n",
    "    'shuffle': True,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "DATA_LOAD_CFG = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0,\n",
    "    'drop_last': False,\n",
    "}\n",
    "\n",
    "RUN_CFG = {\n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 1e-4,\n",
    "    'save_every_n_epoch': 10,\n",
    "    'log_every_n_step': 1,\n",
    "    'on_gpu': torch.cuda.is_available(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = fMRIDataset(**DATASET_CFG)\n",
    "if DATA_SPLIT_CFG['val_ratio'] > 0:\n",
    "    train_set, test_set, val_set = split_data_set(dataset, **DATA_SPLIT_CFG)\n",
    "else:\n",
    "    train_set, test_set = split_data_set(dataset, **DATA_SPLIT_CFG)\n",
    "\n",
    "# Initialize data loaders\n",
    "train_loader = DataLoader(dataset=train_set, **DATA_LOAD_CFG)\n",
    "test_loader = DataLoader(dataset=test_set, **DATA_LOAD_CFG)\n",
    "val_loader = DataLoader(dataset=val_set, **DATA_LOAD_CFG) if DATA_SPLIT_CFG['val_ratio'] > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize model\n",
    "# model = efficientnet_v2_s(weights=None, pretrained=False, num_classes=len(dataset.class_ids))\n",
    "model = SimpleNet()\n",
    "if RUN_CFG['on_gpu']:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=RUN_CFG['learning_rate'])\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_conf_mat(predictions, labels):\n",
    "    conf_matrix = confusion_matrix(labels.argmax(-1).numpy(), predictions.argmax(-1).numpy(),\n",
    "                                   labels=[class_id for class_id in range(labels.shape[-1])],\n",
    "                                   normalize=None)\n",
    "\n",
    "    diag = np.eye(*conf_matrix.shape, dtype=bool)\n",
    "    recall = np.sum(conf_matrix, axis=-1, keepdims=True)\n",
    "    recall = np.where(recall > 0, (conf_matrix[diag] / recall.T).T, np.zeros_like(recall))\n",
    "    precision = np.sum(conf_matrix, axis=0, keepdims=True)\n",
    "    precision = np.where(precision > 0, (conf_matrix[diag] / precision), np.zeros_like(precision))\n",
    "    accuracy = np.sum(conf_matrix[diag]) / np.sum(conf_matrix)\n",
    "\n",
    "    conf_matrix = np.concatenate((conf_matrix, recall), axis=-1)\n",
    "    conf_matrix = np.concatenate((conf_matrix, np.concatenate((precision, np.array([[accuracy]])), axis=-1)), axis=0)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    fig = plt.figure()\n",
    "    labels = list(range(labels.shape[-1]))\n",
    "    xlabels = labels + ['Recall']\n",
    "    ylabels = labels + ['Precision']\n",
    "    fig.ax = sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", linewidths=.2,\n",
    "                         xticklabels=xlabels, yticklabels=ylabels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n",
    "\n",
    "# train_balances = {'0': 0,'1': 0,}\n",
    "# for (_, label) in deepcopy(train_loader):\n",
    "#     train_balances[str(label.argmax(-1).item())] += 1\n",
    "\n",
    "# val_balances = {'0': 0,'1': 0,}\n",
    "# for (_, label) in deepcopy(val_loader):\n",
    "#     val_balances[str(label.argmax(-1).item())] += 1\n",
    "\n",
    "# print(train_balances)\n",
    "# print(val_balances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "logger = SummaryWriter(os.path.join(os.getcwd(), 'logs', datetime.now().strftime('%y%m%d_%H%M%S')))\n",
    "epochs = RUN_CFG['epochs']\n",
    "use_cuda = RUN_CFG['on_gpu']\n",
    "epoch_train_length = len(train_loader)\n",
    "best_val_loss = 999.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training part\n",
    "    model.train()\n",
    "    epoch_loss_train = 0.\n",
    "    with tqdm(total=epoch_train_length, leave=True) as pbar:\n",
    "        for bidx, (fmri, label) in enumerate(train_loader):\n",
    "            if use_cuda:\n",
    "                fmri, label = fmri.cuda(), label.cuda()\n",
    "            label = label.view(-1, label.shape[-1]).contiguous()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = \\\n",
    "            torch.softmax(\n",
    "                model(fmri), dim=-1\n",
    "            )\n",
    "            loss = criterion(prediction, label)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "            optimizer.step()\n",
    "\n",
    "            if (bidx + 1) % RUN_CFG['log_every_n_step'] == 0:\n",
    "                step = epoch * epoch_train_length + bidx + 1\n",
    "                logger.add_scalar('Loss/Train', loss.item(), step)\n",
    "                logger.add_scalar('Accuracy/Train', (prediction.argmax(-1) == label.argmax(-1)).sum() / len(label), step)\n",
    "\n",
    "            epoch_loss_train += loss.item()\n",
    "            pbar.set_postfix({\n",
    "                'Mode': 'Train',\n",
    "                'Epoch': f'{epoch + 1}/{epochs}',\n",
    "                'AvgLoss': epoch_loss_train / (bidx + 1)\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Validation part\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        epoch_loss_eval = 0.\n",
    "        avg_acc = 0.\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        with tqdm(total=len(val_loader), leave=True) as pbar:\n",
    "            for bidx, (fmri, label) in enumerate(val_loader):\n",
    "                if use_cuda:\n",
    "                    fmri, label = fmri.cuda(), label.cuda()\n",
    "                label = label.view(-1, label.shape[-1]).contiguous()\n",
    "                \n",
    "                prediction = \\\n",
    "                torch.softmax(\n",
    "                    model(fmri), dim=-1\n",
    "                )\n",
    "                loss = criterion(prediction, label)\n",
    "\n",
    "                avg_acc += ( ( (prediction.argmax(-1) == label.argmax(-1)).sum() / len(label) ) / len(val_loader) )\n",
    "                predictions.append(prediction.cpu())\n",
    "                labels.append(label.cpu())\n",
    "                \n",
    "                loss /= len(label)\n",
    "                epoch_loss_eval += loss.item()\n",
    "                pbar.set_postfix({\n",
    "                    'Mode': 'Validation',\n",
    "                    'Epoch': f'{epoch + 1}/{epochs}',\n",
    "                    'AvgLoss': epoch_loss_eval / (bidx + 1)\n",
    "                })\n",
    "                pbar.update(1)\n",
    "    \n",
    "    predictions = torch.concatenate(predictions, dim=0)\n",
    "    labels = torch.concatenate(labels, dim=0)\n",
    "    logger.add_figure('Confusion Matrix/Validation', get_conf_mat(predictions, labels), epoch + 1)\n",
    "    logger.add_scalar('Loss/Validation', epoch_loss_eval / len(val_loader), epoch + 1)\n",
    "    logger.add_scalar('Accuracy/Validation', avg_acc, epoch + 1)\n",
    "\n",
    "    if (epoch + 1) % RUN_CFG['save_every_n_epoch'] == 0 or epoch_loss_eval < best_val_loss:\n",
    "        if epoch_loss_eval < best_val_loss:\n",
    "            best_val_loss = epoch_loss_eval\n",
    "            save_name = os.path.join(logger.log_dir, f'model_best_val.pth') \n",
    "        else:\n",
    "            save_name = os.path.join(logger.log_dir, f'model_epoch{epoch}.pth')\n",
    "        \n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': epoch_loss_train,\n",
    "            'epoch': epoch},\n",
    "            save_name\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd96f0c715a1bc4e1bb5609a8ddfb420569e343ee819478f5c3445b6e8b2467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
