{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Pre-Processing Notebook\n",
    "\n",
    "fMRI data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "\n",
    "from nipype import Node, Workflow, Function\n",
    "from nipype.algorithms.misc import Gzip, Gunzip\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nipype.interfaces import spm, fsl\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "\n",
    "from bids.layout import BIDSLayout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPT_PTH = r\".../data/ds003548\"  # need to be set\n",
    "RSLT_PTH = r\".../data/preprocessed\"  # need to be set\n",
    "SINK_DIR = \"datasink\"\n",
    "\n",
    "SUBJECT_LIST = ['01']#, '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16']\n",
    "TASK_LIST = ['emotionalfaces']\n",
    "RUN_LIST = ['1']#, '2', '3', '4', '5']\n",
    "\n",
    "FWHM = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement information collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def collect_subjects_info(root_dir: str, subjects: list = None, tasks: list = None, runs: list = None) -> dict:\n",
    "    layout = BIDSLayout(root_dir)\n",
    "\n",
    "    subjects = layout.get_subjects() if subjects is None else subjects\n",
    "    tasks = layout.get_tasks() if tasks is None else tasks\n",
    "    runs = layout.get_runs() if runs is None else runs\n",
    "\n",
    "    subjects = subjects if len(subjects) > 0 else [None]\n",
    "    tasks = tasks if len(tasks) > 0 else [None]\n",
    "    runs = runs if len(runs) > 0 else [None]\n",
    "\n",
    "    info_dict = {}\n",
    "    root_pth = [root_dir]\n",
    "    file_name = ''\n",
    "    for subject in subjects:\n",
    "        subject_pth = deepcopy(root_pth)\n",
    "        subject_name = deepcopy(file_name)\n",
    "        if subject is not None:\n",
    "            subject_pth += [f'sub-{subject}']\n",
    "            subject_name += f'sub-{subject}'\n",
    "        subject_pth += ['func']\n",
    "\n",
    "        for task in tasks:\n",
    "            task_name = deepcopy(subject_name)\n",
    "            if task is not None:\n",
    "                task_name += f'_task-{task}'\n",
    "\n",
    "            for run in runs:\n",
    "                run_name = deepcopy(task_name)\n",
    "                if run is not None:\n",
    "                    run_name += f'_run-{run}'\n",
    "                \n",
    "                run_name += '_bold.nii.gz'\n",
    "                file_pth = subject_pth + [run_name]\n",
    "\n",
    "                metadata = layout.get_metadata(opj(*file_pth))\n",
    "                info_dict[opj(*file_pth)] = dict(\n",
    "                    TR=metadata['RepetitionTime'],\n",
    "                    SliceTiming=metadata['SliceTiming'],\n",
    "                    SliceOrder=[metadata['SliceTiming'].index(x) for x in sorted(metadata['SliceTiming'])],\n",
    "                    SliceNum=len(metadata['SliceTiming'])\n",
    "                )\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Correction\n",
    "motion_corr = Node(\n",
    "    fsl.MCFLIRT(\n",
    "        mean_vol=True,\n",
    "        save_plots=True,\n",
    "        interpolation='spline',\n",
    "        output_type='NIFTI'\n",
    "    ),\n",
    "    name='motion_corr'\n",
    ")\n",
    "\n",
    "# Slice Timing Correction\n",
    "# TODO: set arguments later -> ref_slice, num_slices, slice_order, time_acquisition, time_repetition\n",
    "slice_timing = Node(\n",
    "    spm.SliceTiming(\n",
    "        time_repetition=2.,\n",
    "        num_slices=35,\n",
    "        ref_slice=17,\n",
    "        time_acquisition=2.-2./35.\n",
    "    ),\n",
    "    name='slice_timing'\n",
    ")\n",
    "\n",
    "# Boundary-Based Coregistration\n",
    "coreg_bbr_mtx = Node(\n",
    "    fsl.FLIRT(\n",
    "        dof=6,\n",
    "        cost='bbr',\n",
    "        schedule='/usr/local/fsl/etc/flirtsch/bbr.sch',\n",
    "        output_type='NIFTI_GZ'\n",
    "    ),\n",
    "    name='coreg_pre'\n",
    ")\n",
    "\n",
    "coreg_warp = Node(\n",
    "    fsl.FLIRT(\n",
    "        interp='spline',\n",
    "        apply_isoxfm=4,\n",
    "        #apply_xfm=True,\n",
    "        output_type='NIFTI'\n",
    "    ),\n",
    "    name='coreg_warp'\n",
    ")\n",
    "\n",
    "smooth = Node(\n",
    "    fsl.Smooth(\n",
    "        fwhm=FWHM,\n",
    "        output_type='NIFTI_GZ'\n",
    "    ),\n",
    "    name='smooth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anatomical Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiss_template = r'/usr/local/spm/spm12/tpm/TPM.nii'\n",
    "norm_template = tiss_template\n",
    "\n",
    "# BET - Skullstrip anatomical Image\n",
    "skull_strip = Node(\n",
    "    fsl.BET(\n",
    "        frac=0.5,\n",
    "        robust=True,\n",
    "        output_type='NIFTI'\n",
    "    ),\n",
    "    name=\"skull_strip\"\n",
    ")\n",
    "\n",
    "# Segmentation\n",
    "GM   = ((tiss_template, 1), 2, (True,True),   (False, False))\n",
    "WM   = ((tiss_template, 2), 2, (True,True),   (False, False))\n",
    "CSF  = ((tiss_template, 3), 2, (True,False),  (False, False))\n",
    "BONE = ((tiss_template, 4), 2, (False,False), (False, False))\n",
    "SOFT = ((tiss_template, 5), 2, (False,False), (False, False))\n",
    "AIR  = ((tiss_template, 6), 2, (False,False), (False, False))\n",
    "segmentation = Node(\n",
    "    spm.NewSegment(\n",
    "        tissues=[GM, WM, CSF, BONE, SOFT]\n",
    "    ),\n",
    "    name='segmentation'\n",
    ")\n",
    "\n",
    "# Threshold (- Threshold WM probability image)\n",
    "threshold_WM = Node(\n",
    "    fsl.Threshold(\n",
    "        thresh=0.5,\n",
    "        args='-bin',\n",
    "        output_type='NIFTI_GZ'\n",
    "    ),\n",
    "    name=\"threshold_WM\"\n",
    ")\n",
    "\n",
    "# Spatial Normalization\n",
    "normalize = Node(\n",
    "    spm.Normalize12(\n",
    "        tpm=norm_template,\n",
    "    ),\n",
    "    name='normalize'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data IO Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_io_objects(run_list, subject_list, task_list):\n",
    "    infosource=Node(IdentityInterface(fields=['subject_id','task_id','zrun_id']), \n",
    "            name=\"infosource\")\n",
    "    infosource.iterables=[('subject_id',subject_list),\n",
    "                    ('task_id',task_list),\n",
    "                    ('zrun_id',run_list)]\n",
    "\n",
    "    # String template with {}-based strings\n",
    "    templates = {'anat': 'sub-{subject_id}/anat/'\n",
    "                    'sub-{subject_id}_T1w.nii.gz',\n",
    "                    'func': 'sub-{subject_id}/func/'\n",
    "                    'sub-{subject_id}_task-{task_id}_run-{zrun_id}_bold.nii.gz'}\n",
    "\n",
    "    # Create SelectFiles node\n",
    "    selectfiles = Node(\n",
    "            SelectFiles(templates,\n",
    "                    base_directory=INPT_PTH,\n",
    "                    sort_filelist=True),\n",
    "            name='selectfiles'\n",
    "    )\n",
    "\n",
    "    # DataSink- creates output folder for important outputs\n",
    "    _substitutions=[('_task_id_','/task-'),\n",
    "            ('_subject_id_','sub-'),\n",
    "            ('_zrun_id_','/run-'),\n",
    "            ('_fwhm_','fwhm-'),\n",
    "            ('_roi',''),\n",
    "            ('_mcf',''),\n",
    "            ('_st',''),\n",
    "            ('_flirt',''),\n",
    "            ('_smooth',''),\n",
    "            ('.nii_mean_reg','_mean'),\n",
    "            ('.nii.par','.par')]\n",
    "\n",
    "    subjFolders=[(f'fwhm-{FWHM}/', f'fwhm-{FWHM}-')]\n",
    "    _substitutions.extend(subjFolders)\n",
    "    # _substitutions = []\n",
    "\n",
    "    datasink=Node(\n",
    "    DataSink(\n",
    "            base_directory=RSLT_PTH,\n",
    "            container=SINK_DIR,\n",
    "            substitutions=_substitutions),\n",
    "    name=\"datasink\"\n",
    "    )\n",
    "    \n",
    "    return infosource, selectfiles, datasink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Process Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_timing(path_id, subject_info):\n",
    "    return subject_info[path_id]['SliceTiming']\n",
    "get_st_node = Node(\n",
    "    Function(\n",
    "        input_names=['path_id', 'subject_info'],\n",
    "        output_names=['output'],\n",
    "        function=get_slice_timing\n",
    "    )\n",
    "    ,name='get_st'\n",
    ")\n",
    "\n",
    "def get_slice_order(path_id, subject_info):\n",
    "    return subject_info[path_id]['SliceOrder']\n",
    "get_so_node = Node(\n",
    "    Function(\n",
    "        input_names=['path_id', 'subject_info'],\n",
    "        output_names=['output'],\n",
    "        function=get_slice_order\n",
    "    )\n",
    "    ,name='get_so'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "run_list = RUN_LIST\n",
    "# subject_list = SUBJECT_LIST\n",
    "task_list = TASK_LIST\n",
    "\n",
    "for subject in SUBJECT_LIST:\n",
    "    subject_list = [subject]\n",
    "    infosource, selectfiles, datasink = get_io_objects(run_list, subject_list, task_list)\n",
    "    subjectinfo = collect_subjects_info(INPT_PTH, subject_list, task_list, run_list)\n",
    "\n",
    "\n",
    "    def get_WM(data):\n",
    "        return data[1][0]\n",
    "\n",
    "    get_so_node.inputs.subject_info = subjectinfo\n",
    "\n",
    "    input_tuple = (infosource, selectfiles, [('subject_id','subject_id'),\n",
    "                                                ('task_id','task_id'),\n",
    "                                                ('zrun_id','zrun_id')])\n",
    "\n",
    "    preproc = Workflow(name='preprocessing', base_dir=opj(RSLT_PTH, \"workingdir\"))\n",
    "    preproc.connect([\n",
    "        input_tuple,\n",
    "        # Anatomical part\n",
    "        (selectfiles, skull_strip, [('anat', 'in_file')]),\n",
    "        (skull_strip, segmentation, [('out_file', 'channel_files')]),\n",
    "        (segmentation, threshold_WM, [(('native_class_images', get_WM), 'in_file')]),\n",
    "\n",
    "        # Functional part\n",
    "        (selectfiles, motion_corr, [('func', 'in_file')]),\n",
    "        (motion_corr, slice_timing, [('out_file', 'in_files')]),\n",
    "        (selectfiles, get_so_node, [('func', 'path_id')]),\n",
    "        (get_so_node, slice_timing, [('output', 'slice_order')]),\n",
    "\n",
    "        # Coregistration\n",
    "        (threshold_WM, coreg_bbr_mtx, [('out_file', 'wm_seg')]),\n",
    "        (skull_strip, coreg_bbr_mtx, [('out_file', 'reference')]),\n",
    "        (motion_corr, coreg_bbr_mtx, [('mean_img', 'in_file')]),\n",
    "\n",
    "        (coreg_bbr_mtx, coreg_warp, [('out_matrix_file', 'in_matrix_file')]),\n",
    "        (skull_strip, coreg_warp, [('out_file', 'reference')]),\n",
    "        (slice_timing, coreg_warp, [('timecorrected_files', 'in_file')]),\n",
    "\n",
    "        # MNI normalization\n",
    "        (coreg_warp, normalize, [('out_file', 'apply_to_files')]),\n",
    "        (skull_strip, normalize, [('out_file', 'image_to_align')]),\n",
    "\n",
    "        # Smoothing\n",
    "        (normalize, smooth, [('normalized_files', 'in_file')]),\n",
    "\n",
    "        # Save data\n",
    "        # (motion_corr, datasink, [('out_file', 'preproc.@motion_corrected')]),\n",
    "        # (motion_corr, datasink, [('mean_img', 'preproc.@motion_mean_img')]),\n",
    "        # (slice_timing, datasink, [('timecorrected_files', 'preproc.@slice_time_corrected')]),\n",
    "\n",
    "        # (skull_strip, datasink, [('out_file', ('preproc.@skull_stripped'))]),\n",
    "        # (segmentation, datasink, [('native_class_images', 'preproc.@segmented')]),\n",
    "        # (threshold_WM, datasink, [('out_file', 'preproc.@thresholded_WM')]),\n",
    "\n",
    "        # (coreg_bbr_mtx, datasink, [('out_matrix_file', 'preproc.@coreg_matrix')]),\n",
    "        # (coreg_warp, datasink, [('out_file', 'preproc.@coregistered')]),\n",
    "\n",
    "        # (normalize, datasink, [('normalized_image', 'preproc.@normalized_anat')]),\n",
    "        (normalize, datasink, [('normalized_files', 'preproc.@normalized_func')]),\n",
    "        (smooth, datasink, [('smoothed_file', 'preproc.@smoothed')])\n",
    "    ])\n",
    "\n",
    "    preproc.run('MultiProc', plugin_args={'n_procs': 3})\n",
    "\n",
    "    # root = opj(RSLT_PTH, \"workingdir\", \"preprocessing\")\n",
    "    # for fname in os.listdir(root):\n",
    "    #     if \"subject_id\" in fname:\n",
    "    #         shutil.rmtree(opj(root, fname), ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd96f0c715a1bc4e1bb5609a8ddfb420569e343ee819478f5c3445b6e8b2467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
